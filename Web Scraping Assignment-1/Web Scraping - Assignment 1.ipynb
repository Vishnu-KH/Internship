{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e25386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to display all the header tags from wikipedia.org and make data frame\n",
    "\n",
    " \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the Wikipedia homepage\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Use Beautiful Soup to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the header tags and extract the text\n",
    "headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "header_text = [header.text for header in headers]\n",
    "\n",
    "# Create a Pandas DataFrame from the header text\n",
    "df = pd.DataFrame({'Header': header_text})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6cbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release) and make data frame\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a request to the IMDB Top 250 page and get the HTML content\n",
    "url = 'https://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Use BeautifulSoup to parse the HTML content and find the movie data\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "movie_data = []\n",
    "for movie in soup.select('tbody.lister-list tr'):\n",
    "    name = movie.find('td', class_='titleColumn').a.text\n",
    "    rating = float(movie.find('td', class_='ratingColumn imdbRating').strong.text)\n",
    "    year = int(movie.find('span', class_='secondaryInfo').text.strip('()'))\n",
    "    movie_data.append((name, rating, year))\n",
    "\n",
    "# Create a pandas data frame from the movie data\n",
    "df = pd.DataFrame(movie_data, columns=['Name', 'Rating', 'Year'])\n",
    "\n",
    "# Display the first 50 rows of the data frame\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of release) and make data frame\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a request to the IMDB Top 250 page and get the HTML content\n",
    "url = 'https://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Use BeautifulSoup to parse the HTML content and find the movie data\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "movie_data = []\n",
    "for movie in soup.select('tbody.lister-list tr'):\n",
    "    name = movie.find('td', class_='titleColumn').a.text\n",
    "    rating = float(movie.find('td', class_='ratingColumn imdbRating').strong.text)\n",
    "    year = int(movie.find('span', class_='secondaryInfo').text.strip('()'))\n",
    "    movie_data.append((name, rating, year))\n",
    "\n",
    "# Create a pandas data frame from the movie data\n",
    "df = pd.DataFrame(movie_data, columns=['Name', 'Rating', 'Year'])\n",
    "\n",
    "# Display the first 50 rows of the data frame\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make data frame.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a request to the Former Presidents page and get the HTML content\n",
    "url = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Use BeautifulSoup to parse the HTML content and find the former presidents data\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "president_data = []\n",
    "for president in soup.select('table tr')[1:]:\n",
    "    name = president.select('td')[0].text.strip()\n",
    "    term_of_office = president.select('td')[1].text.strip()\n",
    "    president_data.append((name, term_of_office))\n",
    "\n",
    "# Create a pandas data frame from the president data\n",
    "df = pd.DataFrame(president_data, columns=['Name', 'Term of Office'])\n",
    "\n",
    "# Display the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame) \n",
    "# a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Scrape the Top 10 ODI teams data and create a data frame\n",
    "url_teams = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response_teams = requests.get(url_teams)\n",
    "soup_teams = BeautifulSoup(response_teams.content, 'html.parser')\n",
    "teams_data = []\n",
    "for team in soup_teams.select('table.table tbody tr')[0:10]:\n",
    "    name = team.select('td.table-body__cell.rankings-table__team')[0].text.strip()\n",
    "    matches = team.select('td.table-body__cell.u-center-text')[0].text.strip()\n",
    "    points = team.select('td.table-body__cell.u-center-text')[1].text.strip()\n",
    "    rating = team.select('td.table-body__cell.u-text-right')[0].text.strip()\n",
    "    teams_data.append((name, matches, points, rating))\n",
    "df_teams = pd.DataFrame(teams_data, columns=['Team', 'Matches', 'Points', 'Rating'])\n",
    "\n",
    "# Scrape the Top 10 ODI batsmen data and create a data frame\n",
    "url_batsmen = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response_batsmen = requests.get(url_batsmen)\n",
    "soup_batsmen = BeautifulSoup(response_batsmen.content, 'html.parser')\n",
    "batsmen_data = []\n",
    "for batsman in soup_batsmen.select('table.table tbody tr')[0:10]:\n",
    "    name = batsman.select('td.table-body__cell.name')[0].text.strip()\n",
    "    team = batsman.select('td.table-body__cell.nationality-logo')[0].text.strip()\n",
    "    rating = batsman.select('td.table-body__cell.rating')[0].text.strip()\n",
    "    batsmen_data.append((name, team, rating))\n",
    "df_batsmen = pd.DataFrame(batsmen_data, columns=['Batsman', 'Team', 'Rating'])\n",
    "\n",
    "# Scrape the Top 10 ODI bowlers data and create a data frame\n",
    "url_bowlers = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response_bowlers = requests.get(url_bowlers)\n",
    "soup_bowlers = BeautifulSoup(response_bowlers.content, 'html.parser')\n",
    "bowlers_data = []\n",
    "for bowler in soup_bowlers.select('table.table tbody tr')[0:10]:\n",
    "    name = bowler.select('td.table-body__cell.name')[0].text.strip()\n",
    "    team = bowler.select('td.table-body__cell.nationality-logo')[0].text.strip()\n",
    "    rating = bowler.select('td.table-body__cell.rating')[0].text.strip()\n",
    "    bowlers_data.append((name, team, rating))\n",
    "df_bowlers = pd.DataFrame(bowlers_data, columns=['Bowler', 'Team', 'Rating'])\n",
    "\n",
    "# Display the data frames\n",
    "print('Top 10 ODI Teams')\n",
    "print(df_teams)\n",
    "print('\\nTop 10 ODI Batsmen')\n",
    "print(df_batsmen)\n",
    "print('\\nTop 10 ODI Bowlers')\n",
    "print(df_bowlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Scrape the Top 10 ODI teams data and create a data frame\n",
    "url_teams = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response_teams = requests.get(url_teams)\n",
    "soup_teams = BeautifulSoup(response_teams.content, 'html.parser')\n",
    "teams_data = []\n",
    "for team in soup_teams.select('table.table tbody tr')[0:10]:\n",
    "    name = team.select('td.table-body__cell.rankings-table__team')[0].text.strip()\n",
    "    matches = team.select('td.table-body__cell.u-center-text')[0].text.strip()\n",
    "    points = team.select('td.table-body__cell.u-center-text')[1].text.strip()\n",
    "    rating = team.select('td.table-body__cell.u-text-right')[0].text.strip()\n",
    "    teams_data.append((name, matches, points, rating))\n",
    "df_teams = pd.DataFrame(teams_data, columns=['Team', 'Matches', 'Points', 'Rating'])\n",
    "\n",
    "# Scrape the Top 10 ODI batting players data and create a data frame\n",
    "url_batsmen = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response_batsmen = requests.get(url_batsmen)\n",
    "soup_batsmen = BeautifulSoup(response_batsmen.content, 'html.parser')\n",
    "batsmen_data = []\n",
    "for batsman in soup_batsmen.select('table.table tbody tr')[0:10]:\n",
    "    name = batsman.select('td.table-body__cell.name')[0].text.strip()\n",
    "    team = batsman.select('td.table-body__cell.nationality-logo')[0].text.strip()\n",
    "    rating = batsman.select('td.table-body__cell.rating')[0].text.strip()\n",
    "    batsmen_data.append((name, team, rating))\n",
    "df_batsmen = pd.DataFrame(batsmen_data, columns=['Batsman', 'Team', 'Rating'])\n",
    "\n",
    "# Scrape the Top 10 ODI all-rounders data and create a data frame\n",
    "url_allrounders = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "response_allrounders = requests.get(url_allrounders)\n",
    "soup_allrounders = BeautifulSoup(response_allrounders.content, 'html.parser')\n",
    "allrounders_data = []\n",
    "for allrounder in soup_allrounders.select('table.table tbody tr')[0:10]:\n",
    "    name = allrounder.select('td.table-body__cell.name')[0].text.strip()\n",
    "    team = allrounder.select('td.table-body__cell.nationality-logo')[0].text.strip()\n",
    "    rating = allrounder.select('td.table-body__cell.rating')[0].text.strip()\n",
    "    allrounders_data.append((name, team, rating))\n",
    "df_allrounders = pd.DataFrame(allrounders_data, columns=['All-Rounder', 'Team', 'Rating'])\n",
    "\n",
    "# Display the data frames\n",
    "print('Top 10 ODI Women\\'s Teams')\n",
    "print(df_teams)\n",
    "print('\\nTop 10 ODI Women\\'s Batting Players')\n",
    "print(df_batsmen)\n",
    "print('\\nTop 10 ODI Women\\'s All-Rounders')\n",
    "print(df_allrounders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n",
    "# i) Headline\n",
    "# ii) Time\n",
    "# iii) News Link\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "headlines = []\n",
    "times = []\n",
    "links = []\n",
    "\n",
    "for article in soup.find_all('div', {'class': 'Card-titleContainer'}):\n",
    "    headline = article.find('a').text.strip()\n",
    "    time = article.find('time').text.strip()\n",
    "    link = article.find('a')['href']\n",
    "    headlines.append(headline)\n",
    "    times.append(time)\n",
    "    links.append(link)\n",
    "\n",
    "df = pd.DataFrame({'Headline': headlines, 'Time': times, 'News Link': links})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articlesScrape below mentioned details and make data frame\n",
    "# i) Paper Title\n",
    "# ii) Authors\n",
    "# iii) Published Date\n",
    "# iv) Paper URL\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "dates = []\n",
    "urls = []\n",
    "\n",
    "for article in soup.find_all('div', {'class': 'pod-listing__body'}):\n",
    "    title = article.find('a', {'class': 'pod-listing__title'}).text.strip()\n",
    "    author_list = article.find_all('a', {'class': 'pod-listing__person'})\n",
    "    author = ', '.join([a.text.strip() for a in author_list])\n",
    "    date = article.find('div', {'class': 'pod-listing__meta'}).text.strip().split(' ')[-1]\n",
    "    url = 'https://www.journals.elsevier.com' + article.find('a', {'class': 'pod-listing__title'})['href']\n",
    "    titles.append(title)\n",
    "    authors.append(author)\n",
    "    dates.append(date)\n",
    "    urls.append(url)\n",
    "\n",
    "df = pd.DataFrame({'Paper Title': titles, 'Authors': authors, 'Published Date': dates, 'Paper URL': urls})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape mentioned details from dineout.co.in and make data frame\n",
    "# i) Restaurant name\n",
    "# ii) Cuisine\n",
    "# iii) Location\n",
    "# iv) Ratings\n",
    "# v) Image URL\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "names = []\n",
    "cuisines = []\n",
    "locations = []\n",
    "ratings = []\n",
    "image_urls = []\n",
    "\n",
    "for restaurant in soup.find_all('div', {'class': 'restnt-info'}):\n",
    "    name = restaurant.find('div', {'class': 'restnt-name'}).text.strip()\n",
    "    cuisine = restaurant.find('div', {'class': 'restnt-oth-info'}).text.strip().split(',')[0]\n",
    "    location = restaurant.find('div', {'class': 'restnt-oth-info'}).text.strip().split(',')[1].strip()\n",
    "    rating = restaurant.find('div', {'class': 'restnt-rating'}).text.strip()\n",
    "    image_url = restaurant.find('img', {'class': 'restnt-img'})['data-src']\n",
    "    names.append(name)\n",
    "    cuisines.append(cuisine)\n",
    "    locations.append(location)\n",
    "    ratings.append(rating)\n",
    "    image_urls.append(image_url)\n",
    "\n",
    "df = pd.DataFrame({'Restaurant name': names, 'Cuisine': cuisines, 'Location': locations, 'Ratings': ratings, 'Image URL': image_urls})\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
