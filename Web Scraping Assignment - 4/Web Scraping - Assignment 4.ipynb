{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e81528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of most viewed videos on YouTube from Wikipedia\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "service = Service('path/to/chromedriver')  # Replace with the path to your ChromeDriver executable\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    table = driver.find_element_by_class_name('wikitable')\n",
    "    rows = table.find_elements_by_tag_name('tr')[1:]\n",
    "    for row in rows:\n",
    "        try:\n",
    "            cells = row.find_elements_by_tag_name('td')\n",
    "            rank = cells[0].text.strip()\n",
    "            name = cells[1].text.strip()\n",
    "            artist = cells[2].text.strip()\n",
    "            views = cells[3].text.strip()\n",
    "            date = cells[4].text.strip()\n",
    "            print(f'{rank}\\t{name}\\t{artist}\\t{date}\\t{views}')\n",
    "        except NoSuchElementException:\n",
    "            print('Error: Data not found for the row.')\n",
    "except NoSuchElementException:\n",
    "    print('Error: Table not found on the page.')\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a56752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details team Indiaâ€™sinternationalfixtures from bcci.tv. \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "service = Service('path/to/chromedriver')  # Replace with the path to your ChromeDriver executable\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Find and click the 'International' link in the main menu\n",
    "    international_link = driver.find_element_by_xpath('//div[@class=\"navigation__drop-down drop-down drop-down--reveal-on-hover\"]//li[@data-nav-index=\"0\"]/div[@class=\"navigation__item__title\"]/a')\n",
    "    international_link.click()\n",
    "\n",
    "    # Find and click the 'Fixtures' link in the sub-menu\n",
    "    fixtures_link = driver.find_element_by_xpath('//div[@class=\"event-list__wrap\"]/button')\n",
    "    fixtures_link.click()\n",
    "\n",
    "    # Find the table containing the fixtures and iterate through each row to extract the details\n",
    "    table = driver.find_element_by_xpath('//div[@class=\"js-list\"]/div[@class=\"js-list__head event-list__header\"]/following-sibling::div[@class=\"js-list\"]/div[@class=\"js-list__body\"]/ul')\n",
    "    rows = table.find_elements_by_tag_name('li')\n",
    "    for row in rows:\n",
    "        try:\n",
    "            match_title = row.find_element_by_xpath('.//strong').text.strip()\n",
    "            series = row.find_element_by_class_name('fixture__tournament-label').text.strip()\n",
    "            place = row.find_element_by_class_name('fixture__info').text.strip().split(',')[1].strip()\n",
    "            date = row.find_element_by_class_name('fixture__datetime').text.strip().split(',')[0].strip()\n",
    "            time = row.find_element_by_class_name('fixture__datetime').text.strip().split(',')[1].strip()\n",
    "            print(f'{match_title}\\t{series}\\t{place}\\t{date}\\t{time}')\n",
    "        except NoSuchElementException:\n",
    "            print('Error: Data not found for the row.')\n",
    "except NoSuchElementException:\n",
    "    print('Error: Element not found on the page.')\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the website\n",
    "driver.get('http://statisticstimes.com/')\n",
    "\n",
    "try:\n",
    "    # Wait for the \"Economy\" link to load and then click on it\n",
    "    economy_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, 'Economy')))\n",
    "    economy_link.click()\n",
    "\n",
    "    # Wait for the \"India\" link to load and then click on it\n",
    "    india_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, 'India')))\n",
    "    india_link.click()\n",
    "\n",
    "    # Wait for the \"GDP of Indian states\" link to load and then click on it\n",
    "    gdp_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, 'GDP of Indian states')))\n",
    "    gdp_link.click()\n",
    "\n",
    "    # Wait for the table to load\n",
    "    table = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'displayTab')))\n",
    "\n",
    "    # Find the table rows and loop through them to extract the data\n",
    "    rows = table.find_elements_by_tag_name('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        # Get the data from the row\n",
    "        data = row.find_elements_by_tag_name('td')\n",
    "        if data:\n",
    "            rank = data[0].text\n",
    "            state = data[1].text\n",
    "            gsdp_1819 = data[2].text\n",
    "            gsdp_1920 = data[3].text\n",
    "            share_1819 = data[4].text\n",
    "            gdp_billion = data[5].text\n",
    "\n",
    "            # Print the data\n",
    "            print(rank, state, gsdp_1819, gsdp_1920, share_1819, gdp_billion)\n",
    "\n",
    "finally:\n",
    "    # Close the browser window\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Scrape the details of trending repositories on Github.com. \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the website\n",
    "driver.get('https://github.com/')\n",
    "\n",
    "try:\n",
    "    # Click on the \"Explore\" menu and wait for the dropdown to load\n",
    "    explore_menu = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//summary[contains(text(), 'Explore')]\")))\n",
    "    explore_menu.click()\n",
    "    explore_dropdown = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"//details[@class='dropdown-menu dropdown-menu-sw']\")))\n",
    "\n",
    "    # Click on the \"Trending\" option in the dropdown\n",
    "    trending_option = explore_dropdown.find_element_by_xpath(\".//a[contains(text(), 'Trending')]\")\n",
    "    trending_option.click()\n",
    "\n",
    "    # Wait for the trending repositories to load\n",
    "    trending_repos = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, \"Box-row\")))\n",
    "\n",
    "    # Loop through each trending repository and extract the required details\n",
    "    for repo in trending_repos:\n",
    "        title = repo.find_element_by_xpath(\".//h1/a\").text\n",
    "        description = repo.find_element_by_xpath(\".//p\").text\n",
    "        lang = repo.find_element_by_xpath(\".//span[@itemprop='programmingLanguage']\").text\n",
    "        try:\n",
    "            contrib = repo.find_element_by_xpath(\".//a[contains(text(), 'Contributors')]\").text\n",
    "        except:\n",
    "            contrib = \"0 contributors\"\n",
    "        \n",
    "        # Print the details\n",
    "        print(\"Title:\", title)\n",
    "        print(\"Description:\", description)\n",
    "        print(\"Language:\", lang)\n",
    "        print(\"Contributors:\", contrib)\n",
    "        print()\n",
    "\n",
    "finally:\n",
    "    # Close the browser window\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of top 100 songs on billiboard.com. \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the website\n",
    "driver.get('https://www.billboard.com/')\n",
    "\n",
    "try:\n",
    "    # Click on the \"Charts\" menu and wait for the dropdown to load\n",
    "    charts_menu = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//nav[@class='header__subnav bg--light']/ul/li[3]\")))\n",
    "    charts_menu.click()\n",
    "    charts_dropdown = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"//nav[@class='charts-nav__menu']/div[2]\")))\n",
    "\n",
    "    # Click on the \"Hot 100\" option in the dropdown\n",
    "    hot100_option = charts_dropdown.find_element_by_xpath(\".//a[contains(text(), 'Hot 100')]\")\n",
    "    hot100_option.click()\n",
    "\n",
    "    # Wait for the chart to load\n",
    "    chart = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='chart-list__wrapper']\")))\n",
    "\n",
    "    # Loop through each song in the chart and extract the required details\n",
    "    for song in chart.find_elements_by_xpath(\".//li[@class='chart-list__element display--flex']\"):\n",
    "        title = song.find_element_by_xpath(\".//span[@class='chart-element__information']/span[@class='chart-element__information__song text--truncate color--primary']\").text\n",
    "        artist = song.find_element_by_xpath(\".//span[@class='chart-element__information']/span[@class='chart-element__information__artist text--truncate color--secondary']\").text\n",
    "        try:\n",
    "            last_week_rank = song.find_element_by_xpath(\".//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "        except:\n",
    "            last_week_rank = \"-\"\n",
    "        try:\n",
    "            peak_rank = song.find_element_by_xpath(\".//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "        except:\n",
    "            peak_rank = \"-\"\n",
    "        weeks_on_board = song.find_element_by_xpath(\".//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "\n",
    "        # Print the details\n",
    "        print(\"Title:\", title)\n",
    "        print(\"Artist:\", artist)\n",
    "        print(\"Last Week Rank:\", last_week_rank.text)\n",
    "        print(\"Peak Rank:\", peak_rank.text)\n",
    "        print(\"Weeks on Board:\", weeks_on_board.text)\n",
    "        print()\n",
    "\n",
    "finally:\n",
    "    # Close the browser window\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of Highest selling novels\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the website\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare')\n",
    "\n",
    "try:\n",
    "    # Wait for the table to load\n",
    "    table = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//table[@class='in-article sortable']\")))\n",
    "\n",
    "    # Loop through each row in the table and extract the required details\n",
    "    for row in table.find_elements_by_xpath(\".//tr\")[1:]:\n",
    "        book_name = row.find_element_by_xpath(\".//td[2]\").text\n",
    "        author_name = row.find_element_by_xpath(\".//td[3]\").text\n",
    "        volumes_sold = row.find_element_by_xpath(\".//td[4]\").text\n",
    "        publisher = row.find_element_by_xpath(\".//td[5]\").text\n",
    "        genre = row.find_element_by_xpath(\".//td[6]\").text\n",
    "\n",
    "        # Print the details\n",
    "        print(\"Book Name:\", book_name)\n",
    "        print(\"Author Name:\", author_name)\n",
    "        print(\"Volumes Sold:\", volumes_sold)\n",
    "        print(\"Publisher:\", publisher)\n",
    "        print(\"Genre:\", genre)\n",
    "        print()\n",
    "\n",
    "finally:\n",
    "    # Close the browser window\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e248b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the website\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "\n",
    "try:\n",
    "    # Wait for the page to load and accept the cookies\n",
    "    cookies_button = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//button[@id='introAgreeButton']\")))\n",
    "    cookies_button.click()\n",
    "\n",
    "    # Wait for the list to load\n",
    "    tv_list = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='lister-list']\")))\n",
    "\n",
    "    # Loop through each TV series in the list and extract the required details\n",
    "    for series in tv_list.find_elements_by_xpath(\".//div[@class='lister-item-content']\"):\n",
    "        name = series.find_element_by_xpath(\".//h3/a\").text\n",
    "        year_span = series.find_element_by_xpath(\".//h3/span[2]\").text\n",
    "        genre = series.find_element_by_xpath(\".//p/span[@class='genre']\").text\n",
    "        runtime = series.find_element_by_xpath(\".//p/span[@class='runtime']\")\n",
    "\n",
    "        # Some entries have no runtime listed\n",
    "        if runtime.text != \"\":\n",
    "            runtime = runtime.text\n",
    "        else:\n",
    "            runtime = \"N/A\"\n",
    "\n",
    "        ratings = series.find_element_by_xpath(\".//div[@class='ipl-rating-star small']\")\n",
    "        rating = ratings.find_element_by_xpath(\".//span[@class='ipl-rating-star__rating']\").text\n",
    "        votes = ratings.find_element_by_xpath(\".//span[@class='ipl-rating-star__total-votes']\")\n",
    "\n",
    "        # Some entries have no votes listed\n",
    "        if votes.text != \"\":\n",
    "            votes = votes.text\n",
    "        else:\n",
    "            votes = \"N/A\"\n",
    "\n",
    "        # Print the details\n",
    "        print(\"Name:\", name)\n",
    "        print(\"Year Span:\", year_span)\n",
    "        print(\"Genre:\", genre)\n",
    "        print(\"Runtime:\", runtime)\n",
    "        print(\"Rating:\", rating)\n",
    "        print(\"Votes:\", votes)\n",
    "        print()\n",
    "\n",
    "finally:\n",
    "    # Close the browser window\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd55b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the website\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "\n",
    "try:\n",
    "    # Click on the \"View ALL Data Sets\" link\n",
    "    view_all_datasets_link = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//span[text()='View ALL Data Sets']\")))\n",
    "    view_all_datasets_link.click()\n",
    "\n",
    "    # Wait for the table to load\n",
    "    table = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//table[@border='1']\")))\n",
    "\n",
    "    # Loop through each row in the table and extract the required details\n",
    "    for row in table.find_elements_by_xpath(\".//tr\")[1:]:\n",
    "        dataset_name = row.find_element_by_xpath(\".//td[1]\").text\n",
    "        data_type = row.find_element_by_xpath(\".//td[2]\").text\n",
    "        task = row.find_element_by_xpath(\".//td[3]\").text\n",
    "        attribute_type = row.find_element_by_xpath(\".//td[4]\").text\n",
    "        no_of_instances = row.find_element_by_xpath(\".//td[5]\").text\n",
    "        no_of_attributes = row.find_element_by_xpath(\".//td[6]\").text\n",
    "        year = row.find_element_by_xpath(\".//td[7]\").text\n",
    "\n",
    "        # Print the details\n",
    "        print(\"Dataset Name:\", dataset_name)\n",
    "        print(\"Data Type:\", data_type)\n",
    "        print(\"Task:\", task)\n",
    "        print(\"Attribute Type:\", attribute_type)\n",
    "        print(\"No of Instances:\", no_of_instances)\n",
    "        print(\"No of Attributes:\", no_of_attributes)\n",
    "        print(\"Year:\", year)\n",
    "        print()\n",
    "\n",
    "finally:\n",
    "    # Close the browser window\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of Data science recruiters\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# create webdriver instance\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# navigate to naukri.com homepage\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "# click on the \"Recruiters\" link\n",
    "recruiters_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//a[@title='Search Recruiters']\")))\n",
    "recruiters_link.click()\n",
    "\n",
    "# switch to the new tab that opens\n",
    "driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "# enter \"Data Science\" into the search box\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//input[@class='sugInp']\")))\n",
    "search_box.send_keys(\"Data Science\")\n",
    "\n",
    "# click on the search button\n",
    "search_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[@class='fl qsbSrch blueBtn']\")))\n",
    "search_button.click()\n",
    "\n",
    "# scrape the details of the recruiters\n",
    "recruiters = driver.find_elements_by_xpath(\"//div[@class='recInfo']\")\n",
    "\n",
    "for recruiter in recruiters:\n",
    "    name = recruiter.find_element_by_xpath(\".//div[@class='recInfo']/div[1]/p[1]/a[1]\").text\n",
    "    designation = recruiter.find_element_by_xpath(\".//div[@class='recInfo']/div[1]/p[1]/span\").text\n",
    "    company = recruiter.find_element_by_xpath(\".//div[@class='recInfo']/div[1]/p[2]/a[1]\").text\n",
    "    skills = recruiter.find_element_by_xpath(\".//div[@class='recInfo']/div[1]/p[2]/span\").text\n",
    "    location = recruiter.find_element_by_xpath(\".//div[@class='recInfo']/div[1]/p[3]/span[1]\").text\n",
    "    \n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Designation: {designation}\")\n",
    "    print(f\"Company: {company}\")\n",
    "    print(f\"Skills: {skills}\")\n",
    "    print(f\"Location: {location}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# close the webdriver instance\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
